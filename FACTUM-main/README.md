# FACTUM-main: Core Implementation

[![arXiv](https://img.shields.io/badge/arXiv-2601.05866v1-b31b1b.svg)](https://arxiv.org/html/2601.05866v1) 
[![Data](https://img.shields.io/badge/Data-NeuCLIR-success)](https://neuclir.github.io/)
[![GitHub](https://img.shields.io/badge/GitHub-Project-blue)](https://github.com/Maximeswd/citation-hallucination)

Welcome to the core directory for the FACTUM framework. This folder contains all the necessary code, scripts, and data for citation hallucination detection using FACTUM.

This guide provides a step-by-step process for setting up the environment, configuring the project, and running the analysis.


## Prerequisites

Before you begin, please ensure you have the following installed:
*   Anaconda/Miniconda or venv to manage the environment.
*   A GPU (preferably NVIDIA for reproducability). Our experiments were specifically run with **NVIDIA V100** GPUs.

---

## Step 1: Create and Activate the Conda Environment

First, create the Conda environment using the provided `environment.yml` file. This will install all the base dependencies.

```bash
# Create the environment from the file
conda env create -f environment.yml

# Activate the newly created environment
conda activate citation
```

### Step 2: Install Core Dependencies
Next, we need to install a few specific packages, including PyTorch with the correct CUDA version and our modified version of the ``transformers`` library. We use ``uv`` for faster installation.

```bash
# Install uv, a fast Python package installer
pip install uv

# Install PyTorch for CUDA 11.7
uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117

# Install Flash Attention for optimized performance
uv pip install flash-attn==2.3.0

# Install other required packages
uv pip install importlib-metadata
```

## Installing the Modified Transformers Library
This is the most critical step. Our method requires a modified version of the Hugging Face ``transformers`` library to extract internal model states. This modified library is included as a directory within this ``FACTUM-main`` folder. Important: Ensure you are in the ``FACTUM-main`` directory before running the following command. The ``-e`` flag installs the package in "editable" mode, linking directly to the source code in this folder.

```bash
# From within the FACTUM-main directory, install our custom transformers package
uv pip install -e transformers
```

### Step 3: Configure Paths
Before running the code, you must verify that the file paths in our script matches your local machine's setup. Please open the following file and edit the paths as needed:

1. ``citation_token_detect_long.py``

Check and update the directories for the following:
- The location of your input dataset. We used the datasets stored at ``~/FACTUM-main/dataset/NeuCLIR24``
- The location where your Hugging Face models are stored. We used models stored in our ``/exp/{user_id}/.cache/huggingface/hub`` directory. Make sure to redirect your huggingface cache path to this directory, otherwise it will be stored in your home directory. 
- The output directory where you want to store the results. We stored our results of the scores here: ``~/FACTUM-main/scale/results/llama3.1-8b_neuclir24`` and here: ``~/FACTUM-main/scale/results/llama3.2-3b_neuclir24``. They were too big to be stored here on GitHub so the folders are empty now. 

### Step 4: Execute the Scoring Job
Once the environment is set up and the paths are configured, you can run the main scoring pipeline with your Slurm batch script. For example:

```bash
# Navigate to the project's root directory (one level up from FACTUM-main)
cd ..

# Submit the job to Slurm
sbatch jobs/citation_token_detect_long.sh
```

**Hardware Requirement**: These jobs were developed and tested on NVIDIA V100 GPUs. We have included sanitary checks in the code (e.g., printing model parameters and hidden states) to help debug potential hardware compatibility issues. Other GPUs may not fully support float16 operations, which can lead to missing values (NaN) in the model's hidden states. We strongly recommend checking the output logs for these sanity checks to ensure the run is valid on your hardware.


### Navigating the Analysis Results
All analysis results and generated plots are stored in the ``scale/`` directory, located at ``~/FACTUM-main/scale``. This directory is organized as follows:
- ``baselines/``: Raw scores for various baseline methods are stored here using the ``run_baselines.py`` script.
- ``ablation_k_{topk%}/``: This directory contains the results for the different experiments conducted using the ``analysis_pruning.py`` script. 
- ``plots/``: This folder contains all the plots and figures generated by the ``plotting.py`` script, providing various visual representations of each of the scores.



### Optional: Downloading New Models from Hugging Face
If you wish to run FACTUM on a new or different model, you will need to download it from the Hugging Face Hub first. The following commands use ``hf_transfer`` for a faster download.

```bash
# Install the Hugging Face Hub library
conda install -c conda-forge huggingface_hub

# Install the accelerated transfer library
uv pip install hf_transfer

# Log in to your Hugging Face account (you will be prompted for a token)
huggingface-cli login

# Download the model, enabling hf_transfer
# Replace <model-id> and <local_dir_to_save_model> with your desired values
HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download <model-id> --local-dir <local_dir_to_save_model> --local-dir-use-symlinks False
```




### Acknowledgements and Citation

The FACTUM framework builds upon the work of the ReDeEP paper for detecting citation hallucinations in long-form long-form Retrieval-Augmented Generation (RAG) specifically. 

We are grateful to the ReDeEP authors for their contribution to the field and for making their scoring work accessible.

-   **Original Paper:** Sun, Z., et al. (2025). *ReDeEP: Detecting Hallucination in Retrieval-Augmented Generation via Mechanistic Interpretability*. ICLR.
-   **Official GitHub Repository:** [https://github.com/Jeryi-Sun/ReDEeP-ICLR](https://github.com/Jeryi-Sun/ReDEeP-ICLR)
